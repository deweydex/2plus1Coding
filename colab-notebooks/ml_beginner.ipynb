{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header"
   },
   "source": [
    "# Machine Learning Classification - Beginner Starter\n",
    "\n",
    "**Welcome to Machine Learning!** This notebook introduces you to training a computer to classify data automatically.\n",
    "\n",
    "## What you're starting with:\n",
    "- A real dataset (iris flowers) already loaded\n",
    "- Code to explore and understand the data\n",
    "- All libraries pre-installed in Colab!\n",
    "\n",
    "## Your tasks:\n",
    "1. Split the data into training and testing sets\n",
    "2. Train a simple classifier\n",
    "3. Make predictions on test data\n",
    "4. Evaluate the model's accuracy\n",
    "5. Visualize the results\n",
    "\n",
    "## How to use this notebook:\n",
    "1. **Run each cell** to see what happens\n",
    "2. **Read the output** and understand what you're seeing\n",
    "3. **Copy code** you want help with to Claude.ai\n",
    "4. **Ask questions** about ML concepts you don't understand\n",
    "5. **Experiment** with different approaches!\n",
    "\n",
    "---\n",
    "\n",
    "## Import Libraries\n",
    "\n",
    "First, we import the tools we need. Colab has these pre-installed!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "imports"
   },
   "outputs": [],
   "source": [
    "# Import machine learning tools\n",
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "print(\"âœ“ Libraries imported successfully!\")\n",
    "print(\"Ready to start machine learning.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "load_data_text"
   },
   "source": [
    "## Load and Explore the Dataset\n",
    "\n",
    "The Iris dataset contains measurements of iris flowers from three species. Given measurements of a flower, we'll train a model to predict its species."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "load_functions"
   },
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "    \"\"\"\n",
    "    Loads the Iris dataset.\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (features, labels, feature_names, target_names)\n",
    "    \"\"\"\n",
    "    iris = load_iris()\n",
    "    \n",
    "    # Features are the measurements\n",
    "    features = iris.data\n",
    "    \n",
    "    # Labels are the species (0, 1, or 2)\n",
    "    labels = iris.target\n",
    "    \n",
    "    # Names of features and targets\n",
    "    feature_names = iris.feature_names\n",
    "    target_names = iris.target_names\n",
    "    \n",
    "    return features, labels, feature_names, target_names\n",
    "\n",
    "\n",
    "def display_dataset_info(features, labels, feature_names, target_names):\n",
    "    \"\"\"\n",
    "    Displays information about the dataset.\n",
    "    \"\"\"\n",
    "    print(\"ðŸ“Š Dataset Information:\")\n",
    "    print(f\"Number of samples: {len(features)}\")\n",
    "    print(f\"Number of features: {len(feature_names)}\")\n",
    "    print(f\"\\nFeature names: {feature_names}\")\n",
    "    print(f\"\\nTarget classes: {target_names}\")\n",
    "    print(f\"Class distribution: {pd.Series(labels).value_counts().to_dict()}\")\n",
    "    \n",
    "    print(\"\\nðŸ“‹ First 5 samples:\")\n",
    "    df = pd.DataFrame(features, columns=feature_names)\n",
    "    df['species'] = [target_names[label] for label in labels]\n",
    "    print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "run_exploration"
   },
   "outputs": [],
   "source": [
    "# Run this cell to load and explore the data!\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"  MACHINE LEARNING: Classification Project\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\nLoading dataset...\\n\")\n",
    "\n",
    "# Load the dataset\n",
    "features, labels, feature_names, target_names = load_dataset()\n",
    "\n",
    "# Display information about it\n",
    "display_dataset_info(features, labels, feature_names, target_names)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"âœ“ Data loaded successfully!\")\n",
    "print(\"Next step: Split into training and testing sets.\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "next_steps"
   },
   "source": [
    "---\n",
    "\n",
    "## Suggested Next Steps\n",
    "\n",
    "### Step 1: Split the Data\n",
    "Ask Claude.ai:\n",
    "> \"Import train_test_split from sklearn.model_selection and split the features and labels into training and testing sets with 80% for training and 20% for testing. Use random_state=42 for reproducibility.\"\n",
    "\n",
    "### Step 2: Train a Model\n",
    "Ask Claude.ai:\n",
    "> \"Import DecisionTreeClassifier from sklearn.tree and create a classifier. Train it on the training data using the fit method.\"\n",
    "\n",
    "### Step 3: Make Predictions\n",
    "Ask Claude.ai:\n",
    "> \"Use the trained model to make predictions on the test data. Display the predicted labels alongside the actual labels for the first 10 samples.\"\n",
    "\n",
    "### Step 4: Evaluate Accuracy\n",
    "Ask Claude.ai:\n",
    "> \"Import accuracy_score from sklearn.metrics and calculate how accurate the model's predictions are. Display the accuracy as a percentage.\"\n",
    "\n",
    "### Step 5: Create a Confusion Matrix\n",
    "Ask Claude.ai:\n",
    "> \"Create a confusion matrix using confusion_matrix from sklearn.metrics to see which classes the model confuses most often. Display it in a readable format or as a heatmap using seaborn.\"\n",
    "\n",
    "---\n",
    "\n",
    "## Your Code Workspace\n",
    "\n",
    "Use the cells below to build your ML pipeline!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "workspace1"
   },
   "outputs": [],
   "source": [
    "# Step 1: Split the data\n",
    "# Add your code here!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "workspace2"
   },
   "outputs": [],
   "source": [
    "# Step 2: Train your model\n",
    "# Add your code here!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "workspace3"
   },
   "outputs": [],
   "source": [
    "# Step 3 & 4: Make predictions and evaluate\n",
    "# Add your code here!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "workspace4"
   },
   "outputs": [],
   "source": [
    "# Step 5: Visualizations\n",
    "# Add your code here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tips"
   },
   "source": [
    "---\n",
    "\n",
    "## Tips for Success\n",
    "\n",
    "- **Run cells in order** - Each cell builds on previous ones\n",
    "- **Read error messages carefully** - They tell you what went wrong\n",
    "- **Test after each step** - Make sure each piece works before moving on\n",
    "- **Experiment!** - Try different models, different test split sizes, etc.\n",
    "- **Ask Claude.ai** - Copy code + error messages when you get stuck\n",
    "\n",
    "Remember: Machine learning is experimental. Try different things and see what works!"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Machine Learning Classification - Beginner",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
